{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gtmQDB6EjReV"
      },
      "outputs": [],
      "source": [
        "# First import the functions we will need\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RVSeTREUEhFx"
      },
      "outputs": [],
      "source": [
        "# This script requires TensorFlow 2 and Python 3.\n",
        "if tf.__version__.split('.')[0] != '2':\n",
        "    raise Exception((f\"The script is developed and tested for tensorflow 2. \"\n",
        "                     f\"Current version: {tf.__version__}\"))\n",
        "\n",
        "if sys.version_info.major < 3:\n",
        "    raise Exception((f\"The script is developed and tested for Python 3. \"\n",
        "                     f\"Current version: {sys.version_info.major}\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O5-58WYokl3"
      },
      "source": [
        "# GradientTape\n",
        "\n",
        "The Calculus is managed by a TensorFlow Gradient Tape. You can learn more about the gradient tape at https://www.tensorflow.org/api_docs/python/tf/GradientTape, and we will discuss it later in the course."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JdhgbGE2j02L"
      },
      "outputs": [],
      "source": [
        "# Define our initial guess\n",
        "INITIAL_W = 10.0\n",
        "INITIAL_B = 10.0\n",
        "\n",
        "# Define our loss function\n",
        "def loss(predicted_y, target_y):\n",
        "  return tf.reduce_mean(tf.square(predicted_y - target_y))\n",
        "\n",
        "# Define our training procedure\n",
        "def train(model, inputs, outputs, learning_rate):\n",
        "  with tf.GradientTape() as t:\n",
        "    current_loss = loss(model(inputs), outputs)\n",
        "    # Here is where you differentiate the model values with respect to the loss function\n",
        "    dw, db = t.gradient(current_loss, [model.w, model.b])\n",
        "    # And here is where you update the model values based on the learning rate chosen\n",
        "    model.w.assign_sub(learning_rate * dw) # -=\n",
        "    model.b.assign_sub(learning_rate * db)\n",
        "    return current_loss\n",
        "\n",
        "# Define our simple linear regression model\n",
        "class Model(object):\n",
        "  def __init__(self):\n",
        "    # Initialize the weights\n",
        "    self.w = tf.Variable(INITIAL_W)\n",
        "    self.b = tf.Variable(INITIAL_B)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return self.w * x + self.b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k3ZvEesEhFy"
      },
      "source": [
        "### Train our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8akmDCoAjgak",
        "outputId": "87afece8-e209-4fe0-fe52-d3b85db5b51c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  0: w=10.00 b=10.00, loss=715.66669\n",
            "Epoch  1: w=4.22 b=7.70, loss=158.93196\n",
            "Epoch  2: w=1.77 b=6.50, loss=51.23996\n",
            "Epoch  3: w=0.76 b=5.78, loss=28.73713\n",
            "Epoch  4: w=0.38 b=5.29, loss=22.56476\n",
            "Epoch  5: w=0.28 b=4.90, loss=19.67445\n",
            "Epoch  6: w=0.28 b=4.57, loss=17.57829\n",
            "Epoch  7: w=0.33 b=4.27, loss=15.78819\n",
            "Epoch  8: w=0.40 b=4.00, loss=14.19614\n",
            "Epoch  9: w=0.48 b=3.74, loss=12.76762\n",
            "Epoch 10: w=0.55 b=3.49, loss=11.48341\n",
            "Epoch 11: w=0.63 b=3.26, loss=10.32847\n",
            "Epoch 12: w=0.70 b=3.04, loss=9.28972\n",
            "Epoch 13: w=0.77 b=2.83, loss=8.35544\n",
            "Epoch 14: w=0.83 b=2.63, loss=7.51512\n",
            "Epoch 15: w=0.89 b=2.44, loss=6.75931\n",
            "Epoch 16: w=0.95 b=2.27, loss=6.07952\n",
            "Epoch 17: w=1.00 b=2.10, loss=5.46809\n",
            "Epoch 18: w=1.05 b=1.94, loss=4.91816\n",
            "Epoch 19: w=1.10 b=1.79, loss=4.42353\n",
            "Epoch 20: w=1.15 b=1.64, loss=3.97865\n",
            "Epoch 21: w=1.19 b=1.51, loss=3.57851\n",
            "Epoch 22: w=1.23 b=1.38, loss=3.21861\n",
            "Epoch 23: w=1.27 b=1.25, loss=2.89491\n",
            "Epoch 24: w=1.31 b=1.14, loss=2.60377\n",
            "Epoch 25: w=1.35 b=1.03, loss=2.34190\n",
            "Epoch 26: w=1.38 b=0.92, loss=2.10637\n",
            "Epoch 27: w=1.41 b=0.82, loss=1.89453\n",
            "Epoch 28: w=1.44 b=0.73, loss=1.70400\n",
            "Epoch 29: w=1.47 b=0.64, loss=1.53262\n",
            "Epoch 30: w=1.50 b=0.56, loss=1.37848\n",
            "Epoch 31: w=1.52 b=0.48, loss=1.23985\n",
            "Epoch 32: w=1.55 b=0.40, loss=1.11516\n",
            "Epoch 33: w=1.57 b=0.33, loss=1.00300\n",
            "Epoch 34: w=1.59 b=0.26, loss=0.90213\n",
            "Epoch 35: w=1.62 b=0.19, loss=0.81140\n",
            "Epoch 36: w=1.63 b=0.13, loss=0.72980\n",
            "Epoch 37: w=1.65 b=0.07, loss=0.65640\n",
            "Epoch 38: w=1.67 b=0.02, loss=0.59038\n",
            "Epoch 39: w=1.69 b=-0.03, loss=0.53101\n",
            "Epoch 40: w=1.70 b=-0.08, loss=0.47760\n",
            "Epoch 41: w=1.72 b=-0.13, loss=0.42957\n",
            "Epoch 42: w=1.73 b=-0.18, loss=0.38637\n",
            "Epoch 43: w=1.75 b=-0.22, loss=0.34751\n",
            "Epoch 44: w=1.76 b=-0.26, loss=0.31256\n",
            "Epoch 45: w=1.77 b=-0.30, loss=0.28113\n",
            "Epoch 46: w=1.79 b=-0.33, loss=0.25285\n",
            "Epoch 47: w=1.80 b=-0.37, loss=0.22742\n",
            "Epoch 48: w=1.81 b=-0.40, loss=0.20455\n",
            "Epoch 49: w=1.82 b=-0.43, loss=0.18398\n"
          ]
        }
      ],
      "source": [
        "# Define our input data and learning rate\n",
        "xs = [-1.0, 0.0, 1.0, 2.0, 3.0, 4.0]\n",
        "ys = [-3.0, -1.0, 1.0, 3.0, 5.0, 7.0]\n",
        "LEARNING_RATE=0.03\n",
        "\n",
        "# Instantiate our model\n",
        "model = Model()\n",
        "\n",
        "# Collect the history of w-values and b-values to plot later\n",
        "list_w, list_b = [], []\n",
        "epochs = range(150)\n",
        "losses = []\n",
        "for epoch in epochs:\n",
        "  list_w.append(model.w.numpy())\n",
        "  list_b.append(model.b.numpy())\n",
        "  current_loss = train(model, xs, ys, learning_rate=LEARNING_RATE)\n",
        "  losses.append(current_loss)\n",
        "  print(f\"Epoch {epoch:2d}: w={list_w[-1]:1.2f} b={list_b[-1]:1.2f}, \"\n",
        "        f\"loss={current_loss:2.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZz5-6BXEhFy"
      },
      "source": [
        "### Plot our trained values over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGgb5grSk8Ax"
      },
      "outputs": [],
      "source": [
        "# Plot the w-values and b-values for each training Epoch against the true values\n",
        "TRUE_w = 2.0\n",
        "TRUE_b = -1.0\n",
        "plt.plot(epochs, list_w, 'r', epochs, list_b, 'b')\n",
        "plt.plot([TRUE_w] * len(epochs), 'r--', [TRUE_b] * len(epochs), 'b--')\n",
        "plt.legend(['w', 'b', 'True w', 'True b'])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Mimimizing-Loss.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}